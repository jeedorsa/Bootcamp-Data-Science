{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23e8a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561b343f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 22:31:01.644495: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-13 22:31:01.678871: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-13 22:31:01.678917: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-13 22:31:01.678944: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-13 22:31:01.685641: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-13 22:31:03.611125: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 218.21 MiB (download: 218.21 MiB, generated: 221.83 MiB, total: 440.05 MiB) to /home/polivares/tensorflow_datasets/tf_flowers/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b0696627614908b9864993f2e32dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset tf_flowers downloaded and prepared to /home/polivares/tensorflow_datasets/tf_flowers/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 22:31:12.682912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.683190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.724011: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.724225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.724333: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.724428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.884107: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.884673: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.884798: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.884884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.884968: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.885054: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.895410: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.895579: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.895688: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.895783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.895889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.896014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 996 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:05:00.0, compute capability: 8.6\n",
      "2024-06-13 22:31:12.896332: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-13 22:31:12.896439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 4177 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "dataset, info = tfds.load(\"tf_flowers\", as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a80797",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set, valid_set, train_set = tfds.load(\"tf_flowers\",split=[\"train[0%:10%]\", \"train[10%:25%]\", \"train[25%:]\"], as_supervised=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da563b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b69ee555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previo a la utilización de nuestro dataset en la red neuronal, la red que utilizaremos provee de\n",
    "# funcionalidades de pre-procesamiento ya incluídas. Por lo tanto, utilizaremos estas funcionalidades\n",
    "# y las dejaremos dentro de una función\n",
    "def preprocess(image, label):\n",
    "    # Cambiaremos las dimensiones de la imagen de entrada\n",
    "    resized_image = tf.image.resize(image, [224, 224]) # Guardamos la imagen con nuevas dimensiones 224x224\n",
    "    # Luego pasamos la imagen modificada en tamaño al preprocesamiento de nuestra red. La red\n",
    "    # que utilizaremos de ejemplo tiene por nombre Xception\n",
    "    final_image = tf.keras.applications.xception.preprocess_input(resized_image)\n",
    "    # Finalmente se retorna una imagen pre procesada (según lo indique el preprocess de xception)\n",
    "    # y su etiqueta\n",
    "    return final_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd9708fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este apartado hacemos los batch de datos directamente desde el dataset cargado por tensorflow\n",
    "batch_size = 32\n",
    "\n",
    "# Mezclamos el dataset \n",
    "train_set = train_set.shuffle(1000)\n",
    "# Tanto para training, test y validación, aplicamos la función de preprocesamiento (preprocess)\n",
    "# y luego generamos los batch de datos\n",
    "train_set = train_set.map(preprocess).batch(batch_size).prefetch(1)\n",
    "test_set = test_set.map(preprocess).batch(batch_size).prefetch(1)\n",
    "valid_set = valid_set.map(preprocess).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04dfb8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá empezamos con transfer learning. Lo que haremos será cargar una arquitectura de red neuronal desde\n",
    "# tensorflow ya entrenada. Eso quiere decir que, no solo estamos cargando la arquitectura, con sus neuronas\n",
    "# y conexiones, sino que también estamos cargando los PESOS DE ENTRENAMIENTO.\n",
    "\n",
    "# Weights indica si utilizaremos pesos pre entrenados con el dataset imagenet o no\n",
    "# include_top es el parámetro que indica explícitamente si quieres o no la capa de salida original\n",
    "# de esta red.\n",
    "# En base_model tenemos cargado nuestro modelo Xception sin la capa de salida. Nosotros podemos\n",
    "# poner NUESTRA PROPIA CAPA(S) DE SALIDA\n",
    "base_model = tf.keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
    "# Acá agregamos nuestras capas adicionales\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = tf.keras.layers.Dense(5, activation=\"softmax\")(avg)\n",
    "\n",
    "# Podemos conectar el input de nuestro modelo base con el output recién generado a través de \n",
    "# un modelo de Keras\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "# En este punto tenemos un nuevo modelo que utiliza como base la arquitectura Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76001e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# También nosotros conversamos que es posible decidir si queremos reentrenar aquellas capas ya entrenadas\n",
    "\n",
    "# Acá vamos capa por capa modificando el parámetro \"trainable\" que permite (o no) reentrenar dicha capa\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False # Esto impide que las capas se re entrenen\n",
    "\n",
    "# Con este for, sobre todas las capas de nuestro modelo, estamos impidiendo que se reentrene\n",
    "# alguna de sus capas ya entrenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af9e8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceso de compilación  (tal cual vimos en las clases anteriores)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f394ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 22:38:21.427747: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/86 [>.............................] - ETA: 3s - loss: 1.6249 - accuracy: 0.1771  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 22:38:22.209393: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x74f334042b40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-13 22:38:22.209415: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-06-13 22:38:22.209418: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-06-13 22:38:22.268101: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 57ms/step - loss: 0.9829 - accuracy: 0.6831 - val_loss: 0.7273 - val_accuracy: 0.7641\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 4s 47ms/step - loss: 0.6083 - accuracy: 0.8180 - val_loss: 0.5988 - val_accuracy: 0.7985\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 4s 47ms/step - loss: 0.5102 - accuracy: 0.8430 - val_loss: 0.5424 - val_accuracy: 0.8094\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 4s 47ms/step - loss: 0.4580 - accuracy: 0.8601 - val_loss: 0.5080 - val_accuracy: 0.8167\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 4s 46ms/step - loss: 0.4237 - accuracy: 0.8674 - val_loss: 0.4867 - val_accuracy: 0.8385\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 4s 47ms/step - loss: 0.3985 - accuracy: 0.8765 - val_loss: 0.4677 - val_accuracy: 0.8348\n",
      "Epoch 7/10\n",
      "86/86 [==============================] - 4s 46ms/step - loss: 0.3782 - accuracy: 0.8801 - val_loss: 0.4530 - val_accuracy: 0.8494\n",
      "Epoch 8/10\n",
      "86/86 [==============================] - 4s 46ms/step - loss: 0.3620 - accuracy: 0.8863 - val_loss: 0.4439 - val_accuracy: 0.8512\n",
      "Epoch 9/10\n",
      "86/86 [==============================] - 4s 47ms/step - loss: 0.3478 - accuracy: 0.8892 - val_loss: 0.4332 - val_accuracy: 0.8566\n",
      "Epoch 10/10\n",
      "86/86 [==============================] - 4s 47ms/step - loss: 0.3352 - accuracy: 0.8950 - val_loss: 0.4233 - val_accuracy: 0.8603\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, epochs=10, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6881fd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 51ms/step - loss: 0.3949 - accuracy: 0.8638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39485207200050354, 0.863760232925415]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec96019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in test_set:\n",
    "    print(\"Etiqueta real\",label)\n",
    "    print(\"Predicción\", model.predict(image))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
